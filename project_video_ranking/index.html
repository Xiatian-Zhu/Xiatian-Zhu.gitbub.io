<!DOCTYPE html><!-- saved from url=(0060)http://twitter.github.com/bootstrap/javascript.html#popovers --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">        <meta charset="utf-8">        <title>Person Re-Identification by Video Ranking</title>        <meta name="viewport" content="width=device-width, initial-scale=1.0">        <meta name="description" content="Xiatian Zhu">        <meta name="author" content="Xiatian Zhu">                <!--<meta name="keywords" content="Chen, Change, Loy, ccloy, ccloy225, C. C. Loy, CC Loy, Chen Change Loy, Loy Chen Change, Abnormal Behaviour Detection, Anomaly Detection, Visual Surveillance, Multiple Cameras, Activity Analysis, Person Re-identification, Security, Random Forest, Active Learning, Mile End Junction Dataset, Underground, Camera Network, Crowded Scene Analysis, Crowd Analysis, Video Analysis, Unusual Event Detection, Crowd Counting, People Counting, Pressure-Sensitive Keystroke Dynamics Dataset, Biometrics, Typing Biometrics" />-->		<meta name="keywords" content="朱霞天, Xiatian Zhu, Xia Tian Zhu, X. Zhu, XT Zhu, XTZhu, Xiatian (Eddy) Zhu, Eddy, 			Visual Surveillance, Video Summarisation, Video Summarization, Video Synopsis,			Camera Network, Multi-Camera Correlation, Feature Coding,			Multi-Source, Multisource, Heterogeneous Sources, Source Correlation,			Random Forest, Clustering Random Forest, Constrained Clustering Random Forest,			Constrained Spectral Clustering, Pairwise Constraint Propogation, Noisy Constraints, Imperfect Oracles,			Constraint Propagation Random Forest, COP-RF" />                <!-- Le styles -->        <link href="../css/bootstrap.css" rel="stylesheet">        <link href="../css/bootstrap-responsive.css" rel="stylesheet">        <link href="../css/docs.css" rel="stylesheet">        <link href="../prettify.css" rel="stylesheet">        <link href="../css/cavan.css" rel="stylesheet">		<link href="../css/Eddy.css" rel="stylesheet">                <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->        <!--[if lt IE 9]>      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>    <![endif]-->        <!-- Le fav and touch icons -->        <link rel="shortcut icon" type="image/ico" href="http://www.eecs.qmul.ac.uk/~xiatian/images/icon/fav.png" />         <link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://twitter.github.com/bootstrap/assets/ico/apple-touch-icon-144-precomposed.png">        <link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://twitter.github.com/bootstrap/assets/ico/apple-touch-icon-114-precomposed.png">        <link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://twitter.github.com/bootstrap/assets/ico/apple-touch-icon-72-precomposed.png">        <link rel="apple-touch-icon-precomposed" href="http://twitter.github.com/bootstrap/assets/ico/apple-touch-icon-57-precomposed.png">                <link href="http://vjs.zencdn.net/c/video-js.css" rel="stylesheet">        <script src="http://vjs.zencdn.net/c/video.js"></script>                        <!-- <script type="text/x-mathjax-config">            MathJax.Hub.Config({            tex2jax: { inlineMath: [['$','$'],['\\(','\\)']] }            });        </script>        <script type='text/javascript' src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>-->            </head>                <body data-spy="scroll" data-target="#navbar" data-twttr-rendered="true">                <div id="navbar" class="navbar navbar-inverse navbar-fixed-top">            <div class="navbar-inner">                <div class="container">                    <button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">                        <span class="icon-bar"></span>                        <span class="icon-bar"></span>                        <span class="icon-bar"></span>                    </button>                    <div class="nav-collapse">                        <ul class="nav">                            <li><a href="../index.html"><strong>Home</strong></a></li>                            <!--<li><a href="../about.html"><strong>About Me</strong></a></li>-->                            <!--<li><a href="../publication.html"><strong>Publication</strong></a></li>-->							<li><a href="../index.html#PUBLICATION"><strong>Publication</strong></a></li>                            <li><a href="../download.html"><strong>Download</strong></a></li>                        </ul>                    </div><!--/.nav-collapse -->                </div>            </div>        </div>                                        <div class="container">            <div class="tooltip-demo">                                <section id="overview_diagram">                    <div class="page-header">                        <h1>Person Re-Identification by Video Ranking <small>TPAMI'16, ECCV'14</small></h1>                    </div>                                        <!-- <div class="row-fluid">            <div class="thumbnail">                <img src="./images/overview.png" alt="">            </div>          </div> -->                </section>                                <!-- Content        ================================================== -->                <section>                                        <h2>Introduction <small></small></h2>                    <p>                        Current person re-identification (re-id) methods typically rely						on single-frame imagery features, and ignore space-time information						from image sequences. Single-frame (single-shot) visual appearance matching						is inherently limited for person re-id in public spaces due to visual						ambiguity arising from non-overlapping camera views where viewpoint						and lighting changes can cause significant appearance variation. In this						work, we present a novel model to automatically select the most discriminative						video fragments from noisy image sequences of people where						more reliable space-time features can be extracted, whilst simultaneously						to learn a video ranking function for person re-id. Also, we introduce						a new image sequence re-id dataset (iLIDS-VID) based on the						i-LIDS MCT benchmark data. Using the iLIDS-VID and PRID 2011 sequence						re-id datasets, we extensively conducted comparative evaluations						to demonstrate the advantages of the proposed model over contemporary						gait recognition, holistic image sequence matching and state-of-the-art						single-shot/multi-shot based re-id methods.                    </p>                                    </section>                                <section>                    <h2>Contribution Highlights <small></small></h2>		                    <ol>                        <li>							We derive a multi-fragments							based space-time feature representation of image sequences of people. This representation is based on a combination of HOG3D features and optic 							ow energy profile over each image sequence, designed to break down automatically unregulated video clips of people into multiple fragments.						</li>                        <li>							We propose a discriminative video ranking model for cross-view re-identification by simultaneously							selecting and matching more reliable space-time features from video fragments.							The model is formulated using a multi-instance ranking strategy for learning							from pairs of image sequences over non-overlapping camera views. This method							can significantly relax the strict assumptions required by gait recognition techniques.						</li>						<li>							We introduce a new image sequence based person re-identification							dataset called iLIDS-VID, extracted from the i-LIDS Multiple-Camera Tracking Scenario (MCTS). To our knowledge, this is the largest image sequence							based re-identification dataset that is publically available.						</li>                    </ol>                                    </section>                                <section>                    <h2>Citation<small></small></h2>                    <ol>                        <li>							Person Re-Identification by Video Ranking.							<br/>							T. Wang, S. Gong, X. Zhu, and S. Wang. 							<br/>							In Proc. European Conference on Computer Vision, Zurich, Switzerland, September 2014. &nbsp;							<br/>							<!-- paper download -->							[<a href='../papers/ECCV14/WangEtAl_ECCV14.pdf'>PDF</a>] &nbsp;							[<a href='CMC_ECCV2014_v2.zip'>CMC</a>] &nbsp;							[<a href='splits_ECCV14.zip'>Data Splits</a>] &nbsp;							[<a href='spotlight_video_ranking.avi'>Spotlight Video</a>] &nbsp;							<!--[<a href='../papers/ECCV14/poster_CVPR14.pdf'>Poster</a>] &nbsp;-->						</li>						<li>							Person Re-Identification by Discriminative Selection in Video Ranking.							<br/>							T. Wang, S. Gong, X. Zhu, and S. Wang. 							<br/>							IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 38, No. 12, pp. 2501-2514, December 2016. &nbsp;							<br/>							<!-- paper download -->							[<a href='../papers/TPAMI16/WangEtAl_PAMI2016.pdf'>PDF</a>] &nbsp;							[<a href='http://arxiv.org/pdf/1601.06260v1.pdf'>arXiv</a>] &nbsp;							[<a href='CMC_TPAMI2016.zip'>CMC</a>] &nbsp;							<!--[<a href='../papers/ECCV14/poster_CVPR14.pdf'>Poster</a>] &nbsp;-->						</li>                    </ol>                </section>                                <section>                    <h2>Images<small></small></h2>                    <!-- Put other representative images here -->                    <!-- Again, please put the images in to ./images -->                    <!--div class="row-fluid">						                        <div class="span4">                            <a href="./images/spectral_clustering.png" class="thumbnail" rel="tooltip" data-placement="top" title="Click for large image">                                <img src="./images/spectral_clustering.png"   alt="">                            </a>                        </div>						                        <div class="span8">                            <h3><strong>Problem definition:</strong></h3>                            <p>								How to construct <em>robust</em> and <em>meaningful</em> affinity matrices/graphs is crucial for data spectral clustering. 								This is because the given data are often challenging due to being high-dimensional, heterogeneous and noisy.		`					</p>                        </div>                    </div-->                                        <p></p> <!-- this is to separate different rows of figures -->			                    <div class="row-fluid">						                        <div class="span6">                            <a href="./images/framework.png" class="thumbnail" rel="tooltip" data-placement="top" title="Click for large image">                                <img src="./images/framework.png"   alt="">                            </a>                        </div>					                        <div class="span6">  							<h3><strong>Overview of our approach: </strong></h3>						                            <p>								Discriminative Video Ranking (DVR) model learning pipeline:								<ol>									<li>										Generating candidate fragment pools by Flow Energy Profiling (FEP)									</li>																		<li>										Creating candidate fragment pairs as positive and negative instances									</li>																		<li>										Simultaneously selecting and ranking the most discriminative fragment pairs.									</li>								</ol>                            </p>                        </div>                    </div>                                        <p></p> <!-- this is to separate different rows of figures -->			                    <div class="row-fluid">                        <div class="span6">                            <a href="./images/datasets-H.png" class="thumbnail" rel="tooltip" data-placement="top" title="Click for large image">                                <img src="./images/datasets-H.png"   alt="">                            </a>                        </div>						                        <div class="span6">    							<h3><strong>Datasets: </strong></h3>                            <p>								Examples of two image sequence based re-id datasets.							</p>                        </div>                    </div>                                        <p></p> <!-- this is to separate different rows of figures -->			                    <div class="row-fluid">											<div class="span6">                            <a href="./images/TableGaitAndDTW.png" class="thumbnail" rel="tooltip" data-placement="top" title="Click for large image">                                <img src="./images/TableGaitAndDTW.png"   alt="">                            </a>                        </div>												<div class="span6"> 							<h3><strong>Evaluation:</strong></h3>                            <p>Comparison of person re-id performance between different methods using Cumulated Matching Characteristics (CMC).</p>                        </div>                                            </div>										<div class="row-fluid">											<div class="span6">                            <a href="./images/Table-state-of-art.png" class="thumbnail" rel="tooltip" data-placement="top" title="Click for large image">                                <img src="./images/Table-state-of-art.png"   alt="">                            </a>                        </div>						                                          </div>										<div class="row-fluid">											<div class="span6">                            <a href="./images/Table-combined.png" class="thumbnail" rel="tooltip" data-placement="top" title="Click for large image">                                <img src="./images/Table-combined.png"   alt="">                            </a>                        </div>						                                          </div>                                    </section>                                <section>					<h2>Dataset <small></small></h2>                    <div class="row">                        <div class="span6">                            <a href="../downloads_qmul_iLIDS-VID_ReID_dataset.html" class="thumbnail" rel="tooltip" data-placement="top" data-original-title="Dataset details ...">                                <img src="../iLIDS-VID/samples/thumbnail.png" width="560" alt="">                             </a>                        </div>                        <div class="span6">                            <strong>iLIDS Video re-IDentification (iLIDS-VID) Dataset</strong>                            <p>                                An image sequence based person re-identification dataset captured in a crowded public space.                            </p>                            <a href="http://www.eecs.qmul.ac.uk/~xiatian/downloads_qmul_iLIDS-VID_ReID_dataset.html">Details ... </a>                         </div>                    </div>                    <!--div class="row">                        <div class="span4">                                                    </div>                        <div class="span8">                            <strong>C++/MATLAB code for unsupervised clustering random forest</strong>                            <p>                            C++ codes with MATLAB wrapper for unsupervised clustering forest. 							It can construct robust affinity graph for spectral clustering or manifold ranking. 							Apart from the proposed approach, the code also includes binary affinity described in 							A. Criminisi and J. Shotton, Decision Forests for Computer Vision and  Medical Image Analysis, Springer 2013. 							A demo is included.							</p>							<p>								<a href="./code/robustGraphs.zip" class="btn btn-success"><i class="icon-download-alt icon-white"></i> Downlo